{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "344a1125",
   "metadata": {},
   "source": [
    "# Formatting\n",
    "\n",
    "When all the tardis simulations are done, we will format the data into tersors, and split them into training and testing data set, and apply a data mask onto the spectra to mimic the telescope spectrograph wavelength limit.  \n",
    "I have collected all the input data and TARDIS simulated spectra into the folder \"ContSend\".  \n",
    "\n",
    "\n",
    "Please don't run this notebook unless you know what you are doing, because there are already some files, especially the training and testing data set, used in other notebooks and are directly related to the results in the paper.  \n",
    "\n",
    "\n",
    "In the \"ContSend\" folder, the \"elemList.npy\" file and the \"auxiList.npy\" file saves the element abundance and auxiliary data (time after explosion, luminosity, density, photosphere velocity), and the structure is the same as in the \"1_ElemPrepare\" notebook. There are also \"photList.npy\" file saves the photosphere temperature, \"tempList.npy\" saves the temperature structure. The \"specList.npy\" file saves the simulated spectra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b66d9a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_248437/3971067387.py:8: DeprecationWarning: Please use `gaussian_filter1d` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ff948a",
   "metadata": {},
   "source": [
    "# The Mask\n",
    "\n",
    "Here I store the beginning and ending wavelengths of all the observed spectra on WISEREP (as of year 2020) into the \"minList.npy\" and \"maxList.npy\" file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2784e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "minList=np.load('minList.npy')\n",
    "maxList=np.load('maxList.npy')\n",
    "wave=np.genfromtxt('Prim.ascii')[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5271c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalizer(spec,shortwave=6500,longwave=7500):\n",
    "    small=np.argmin(abs(spec[:,0]-shortwave))\n",
    "    long=np.argmin(abs(spec[:,0]-longwave))\n",
    "    if small<long:spec[:,1]=spec[:,1]/np.average(spec[small:long,1])\n",
    "    if small>long:spec[:,1]=spec[:,1]/np.average(spec[long:small,1])\n",
    "    return spec\n",
    "def windowSpec(spec):\n",
    "    spFunc=interp1d(spec[:,0],spec[:,1],fill_value=np.nan,bounds_error=False)\n",
    "    smFlux=spFunc(wave)\n",
    "    smFlux=smFlux/np.nanmean(smFlux)\n",
    "    smFlux[np.isnan(smFlux)]=-1\n",
    "    return np.array([wave,smFlux]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9270604a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_248437/2432315316.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if small>long:spec[:,1]=spec[:,1]/np.average(spec[long:small,1])\n"
     ]
    }
   ],
   "source": [
    "Xraw=np.load('ContSend/specList.npy')\n",
    "Y=np.load('ContSend/elemList.npy')\n",
    "X=[]\n",
    "for flux in Xraw:\n",
    "    spec=np.array([wave,flux]).T\n",
    "    spec=Normalizer(spec)\n",
    "    X.append(spec[:,1])\n",
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a468306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                      | 1/112090 [00:00<4:01:44,  7.73it/s]/tmp/ipykernel_248437/2432315316.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  smFlux=smFlux/np.nanmean(smFlux)\n",
      "100%|█████████████████████████████████| 112090/112090 [00:15<00:00, 7038.77it/s]\n"
     ]
    }
   ],
   "source": [
    "Xc=[]\n",
    "for i in tqdm.tqdm(range(len(X))):\n",
    "    spec=np.array([wave,X[i]]).T\n",
    "    spec=windowSpec(spec)\n",
    "    Xc.append(spec[:,1].reshape([-1,1]))\n",
    "Xc=np.array(Xc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db0031",
   "metadata": {},
   "source": [
    "# The Formatted Data\n",
    "\n",
    "Now, the data stored in \"Xc.npy\" file contains the TARDIS simulated spectra, the NaN values are masked, and all the flux values are normalized to between 0 and 10 (approximately), so there is no total luminosity information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c608e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('DataSet/110KRun/Xc.npy',Xc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef9f517",
   "metadata": {},
   "source": [
    "# The Mask\n",
    "Here I apply the observational mask onto the simulated data. Now, the beginning and the ending of the spectra will be filled with -1. The observational mask is randomly picked from the WISEREP spectra maximum and minimum wavelength list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecb06dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000.0000000000002"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for iterRun in range(1,5):\n",
    "    Xc=[]\n",
    "    for i in tqdm.tqdm(range(len(X))):\n",
    "        flux=X[i].copy()\n",
    "        while True:\n",
    "            chooseWave=np.random.randint(len(minList))\n",
    "            choLaW=np.argmin(np.abs(maxList[chooseWave]-wave))\n",
    "            choSmW=np.argmin(np.abs(minList[chooseWave]-wave))\n",
    "            if choLaW+100<choSmW:break\n",
    "        spec=np.array([wave,flux.flatten()]).T\n",
    "        spec=spec[choLaW:choSmW]\n",
    "        spec=windowSpec(spec)\n",
    "        Xc.append(spec[:,1].reshape([-1,1]))\n",
    "    Xc=np.array(Xc)\n",
    "    np.save('DataSet/110KRun/Xc_'+str(iterRun)+'.npy',Xc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53dba4",
   "metadata": {},
   "source": [
    "# Train and Test\n",
    "Here we split the data into the training and testing data set. To notice, if a supernova model is in the training data set, then all the spectra, with or without observational mask of this supernova model should be in the training data set. Same rule also applys to the testing data set. This is to prevent data leakage which could cause a unreal high testing performance.  \n",
    "Finally, the data will be saved into \"DataSet\" folder, and they will be used to train and validate the neural networks.  \n",
    "The normalization parameters, which are the mean and the standard error of the luminosity, time after explosion, photosphere velocity, density profile values, are stored in \"YauxNorm.npy\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.load('ContSend/elemList.npy')\n",
    "Yaux=np.load('ContSend/auxiList.npy')\n",
    "YauxNorm=np.array([Yaux.mean(axis=0),Yaux.std(axis=0)])\n",
    "Yaux=(Yaux-YauxNorm[0])/YauxNorm[1]\n",
    "\n",
    "XcList=[np.load('DataSet/110KRun/Xc.npy'),np.load('DataSet/110KRun/Xc_1.npy'),np.load('DataSet/110KRun/Xc_2.npy'),\\\n",
    "        np.load('DataSet/110KRun/Xc_3.npy'),np.load('DataSet/110KRun/Xc_4.npy')]\n",
    "X_train=[]\n",
    "X_test=[]\n",
    "Y_train=[]\n",
    "Y_test=[]\n",
    "Yaux_train=[]\n",
    "Yaux_test=[]\n",
    "\n",
    "trainMask=np.random.choice([True,False],p=[0.8,0.2],size=len(XcList[0]))\n",
    "for i in range(len(XcList)):\n",
    "    X_train.append(XcList[i][trainMask])\n",
    "    X_test.append(XcList[i][trainMask==False])\n",
    "    Y_train.append(Y[trainMask])\n",
    "    Y_test.append(Y[trainMask==False])\n",
    "    Yaux_train.append(Yaux[trainMask])\n",
    "    Yaux_test.append(Yaux[trainMask==False])\n",
    "X_train=np.concatenate(X_train)\n",
    "X_test=np.concatenate(X_test)\n",
    "Y_train=np.concatenate(Y_train)\n",
    "Y_test=np.concatenate(Y_test)\n",
    "Yaux_train=np.concatenate(Yaux_train)\n",
    "Yaux_test=np.concatenate(Yaux_test)\n",
    "\n",
    "mask=(np.max(X_train,axis=(1,2))<15)\n",
    "X_train=X_train[mask]\n",
    "Y_train=Y_train[mask]\n",
    "Yaux_train=Yaux_train[mask]\n",
    "mask=(np.max(X_test,axis=(1,2))<15)\n",
    "X_test=X_test[mask]\n",
    "Y_test=Y_test[mask]\n",
    "Yaux_test=Yaux_test[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('DataSet/110KRun/X_train.npy',X_train)\n",
    "np.save('DataSet/110KRun/X_test.npy',X_test)\n",
    "np.save('DataSet/110KRun/Y_train.npy',Y_train)\n",
    "np.save('DataSet/110KRun/Y_test.npy',Y_test)\n",
    "np.save('DataSet/110KRun/Yaux_train.npy',Yaux_train)\n",
    "np.save('DataSet/110KRun/Yaux_test.npy',Yaux_test)\n",
    "np.save('DataSet/110KRun/YauxNorm.npy',YauxNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6093c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cb361e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0523d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-keras] *",
   "language": "python",
   "name": "conda-env-.conda-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
